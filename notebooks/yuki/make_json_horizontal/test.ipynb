{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dbacce2-254b-4b8b-aca0-59a31827b875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "def get_horizontal_frames(num_image, frames):\n",
    "    equator_threshold = 0.4\n",
    "    center_pt = np.zeros(3)\n",
    "    \n",
    "    # initialization of dict_list\n",
    "    selected_frame_dict_list = []\n",
    "    for i in range(num_image):\n",
    "        s_f_dict = {}\n",
    "        theta = 2*np.pi/num_image * i\n",
    "        base_vector = np.array([np.sin(theta), np.cos(theta)])\n",
    "        s_f_dict[\"base_vector\"] = base_vector\n",
    "        s_f_dict[\"selected_frame_inner_product\"] = -1000\n",
    "        s_f_dict[\"selected_frame\"] = frames[0]\n",
    "        selected_frame_dict_list.append(s_f_dict)\n",
    "\n",
    "    # select num_image frames\n",
    "    for frame in frames:\n",
    "        transform_matrix = frame[\"transform_matrix\"]\n",
    "        t_m_array = np.array(transform_matrix) # =~ c2w ?\n",
    "\n",
    "        # z = t_m_array[2, 3] height??\n",
    "        if t_m_array[2,3] >= equator_threshold:\n",
    "            continue\n",
    "            \n",
    "        # xy plane vector\n",
    "        vector = t_m_array[[0, 1], 3] # - center_pt[[2, 1]]\n",
    "        direction = vector / np.linalg.norm(vector)\n",
    "\n",
    "        # inner product =~ 1 -> select as a frame\n",
    "        for i, s_f_dict in enumerate(selected_frame_dict_list):\n",
    "            # inner_product = np.dot(direction, s_f_dict[\"base_vector\"])\n",
    "            inner_product = np.dot(direction, s_f_dict[\"base_vector\"])\n",
    "            if s_f_dict[\"selected_frame_inner_product\"] < inner_product:\n",
    "                selected_frame_dict_list[i][\"selected_frame\"] = frame\n",
    "                selected_frame_dict_list[i][\"selected_frame_inner_product\"] = inner_product\n",
    "\n",
    "    selected_frames = [s_f_dict[\"selected_frame\"] for s_f_dict in selected_frame_dict_list]\n",
    "    return selected_frames\n",
    "\n",
    "def modify_dict_data_horizontal(num_image, dict_data):\n",
    "    frames = dict_data[\"frames\"]\n",
    "\n",
    "    selected_frames = get_horizontal_frames(num_image, frames)\n",
    "\n",
    "    modified_dict_data = copy.deepcopy(dict_data)\n",
    "    modified_dict_data[\"frames\"] = selected_frames\n",
    "    return modified_dict_data\n",
    "    \n",
    "def get_dict_data_from_json_path(input_json_path):\n",
    "    with open(input_json_path, 'r') as f:\n",
    "        dict_data = json.load(f)\n",
    "    return dict_data\n",
    "\n",
    "def save_dict_data(dict_data, output_json_path):\n",
    "    with open(output_json_path, \"w\") as f:\n",
    "        json.dump(dict_data, f)\n",
    "        #json.dump(dict_data, f, indent=4)\n",
    "        \n",
    "def do_io_json_horizontal(in_dir, out_dir):\n",
    "    in_json_path = f\"{in_dir}/train_all.json\"\n",
    "    dict_data = get_dict_data_from_json_path(in_json_path)\n",
    "    \n",
    "    for num_image in [3, 10]:\n",
    "        modified_dict_data = modify_dict_data_horizontal(num_image, dict_data)\n",
    "        out_json_path = f\"{out_dir}/train_all_{num_image}_horizontal.json\"\n",
    "        save_dict_data(modified_dict_data, out_json_path)\n",
    "    \n",
    "def make_json_all_scene():\n",
    "    path = \"/home/ccl/Datasets/NeRF/ScanNerf/\"\n",
    "    scene_list = sorted(os.listdir(path))\n",
    "\n",
    "    for scene in scene_list:\n",
    "        input_dir_path = f\"{path}{scene}/\"\n",
    "\n",
    "        # for test\n",
    "        new_dir = f\"./train_horizontal\"\n",
    "        if not os.path.exists(new_dir):\n",
    "            os.mkdir(new_dir)\n",
    "\n",
    "        new_dir += f\"/{scene}\"\n",
    "        if not os.path.exists(new_dir):\n",
    "            os.mkdir(new_dir)\n",
    "\n",
    "        # for actual purpose\n",
    "        # new_dir = f\"{path}{scene}/\" \n",
    "        \n",
    "        do_io_json_horizontal(input_dir, new_dir)\n",
    "        \n",
    "# image\n",
    "ckpt_path = \"/home/ccl/Datasets/NeRF/ScanNerf/\"\n",
    "scene_list = sorted(os.listdir(ckpt_path))\n",
    "\n",
    "def copy_image_of_json(in_json_path, in_image_dir, out_dir, scene):\n",
    "    with open(in_json_path, 'r') as f:\n",
    "        dict_data = json.load(f)\n",
    "    frames = dict_data[\"frames\"]\n",
    "    \n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    \n",
    "    imgs = []\n",
    "    for i, frame in enumerate(frames):\n",
    "        file_path = frame[\"file_path\"]\n",
    "        img_path = f\"{in_image_dir}/{file_path}.png\"\n",
    "        img = Image.open(img_path)\n",
    "        img.save(f\"{out_dir}/{i}_{os.path.basename(file_path)}.png\")\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs[0].save(f\"{out_dir}/{scene}.gif\",save_all=True, append_images=imgs[1:],optimize=True, duration=200, loop=0)\n",
    "\n",
    "    \n",
    "def save_image_jsons(num_train_image):\n",
    "    for scene in scene_list:\n",
    "        in_json_dir = f\"./train_horizontal/{scene}/\"\n",
    "        in_json_path = f\"{in_json_dir}/train_all_{num_train_image}_horizontal.json\"\n",
    "        in_image_dir = f\"/home/ccl/Datasets/NeRF/ScanNerf/{scene}\"\n",
    "        out_dir = f\"{in_json_dir}/{num_train_image}\"\n",
    "        copy_image_of_json(in_json_path, in_image_dir, out_dir, scene)\n",
    "\n",
    "        \n",
    "# for test!!! only 1 scene(airplane1)\n",
    "\n",
    "def make_json_img_test(scene):\n",
    "    train_data_ckpt_dir = \"/home/ccl/Datasets/NeRF/ScanNerf\"\n",
    "    in_dir = f\"{train_data_ckpt_dir}/{scene}/\"\n",
    "    in_dir = \".\"\n",
    "    out_dir = f\"./test/{scene}\"\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    do_io_json_horizontal(in_dir, out_dir)\n",
    "\n",
    "    for num_train_image in [3, 10]:\n",
    "        in_json_dir = f\"./test/{scene}/\"\n",
    "        in_json_path = f\"{in_json_dir}/train_all_{num_train_image}_horizontal.json\"\n",
    "        in_img_dir = f\"/home/ccl/Datasets/NeRF/ScanNerf/{scene}\"\n",
    "        out_img_dir = f\"{out_dir}/{num_train_image}\"\n",
    "\n",
    "        copy_image_of_json(in_json_path, in_img_dir, out_img_dir, scene)\n",
    "        \n",
    "make_json_img_test(\"airplane1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64f47d8f-5739-4347-8ffe-cfaf5a01ff71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n",
      "0.6283185307179586 36.0\n",
      "1.2566370614359172 72.0\n",
      "1.8849555921538759 108.0\n",
      "2.5132741228718345 144.0\n",
      "3.141592653589793 180.0\n",
      "3.7699111843077517 216.0\n",
      "4.39822971502571 252.0\n",
      "5.026548245743669 288.0\n",
      "5.654866776461628 324.0\n"
     ]
    }
   ],
   "source": [
    "num_image = 10\n",
    "\n",
    "for i in range(num_image):\n",
    "    s_f_dict = {}\n",
    "    theta = 2*np.pi/num_image * i\n",
    "    base_vector = np.array([np.sin(theta), np.cos(theta)])\n",
    "    s_f_dict[\"base_vector\"] = base_vector\n",
    "    print(theta, np.degrees(theta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4605d4f-6cb4-4cd8-904d-de1c9b2b6518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
